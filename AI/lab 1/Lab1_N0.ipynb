{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import metrics\n",
    "#from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    x_train = np.load(os.path.join(folder, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(folder, 'y_train.npy'))    \n",
    "    x_test = np.load(os.path.join(folder, 'x_test.npy'))    \n",
    "    y_test = np.load(os.path.join(folder, 'y_test.npy'))    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        # dim - размерность входных данных.\n",
    "        self.w = np.random.randn(dim, 1) / np.sqrt(dim) #w = weights\n",
    "        self.b = np.zeros((1,)) #b = bias\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        x = x.dot(self.w) + self.b  # logits\n",
    "        p = sigmoid(x)  # probabilities\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "        \n",
    "    def fit(self, x, y, iters=100, lr=0.01):\n",
    "        # x - np.array размерности [N, dim]\n",
    "        #     Массив входных признаков.\n",
    "        # y - np.array размернсоти [N]\n",
    "        #     Массив меток (правильных ответов).\n",
    "        # Алгоритм градиентного спуска.\n",
    "        # Минимизируется бинарная кросс-энтропия.\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Применение логистической регрессии (несбалансированные данные)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Создание и обучение логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указание: производить нормализацию данных не нужно, это часть задания.\n",
    "x_train, y_train, x_test, y_test = load_data('dataset1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте модель логистической регрессии и обучите её, используя метод fit.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели =  96%\n"
     ]
    }
   ],
   "source": [
    "# Получите предсказания на тестовой выборке и оцените точность модели, \n",
    "# используя accuracy_score из пакета SciKit-Learn.\n",
    "print(\"Точность модели = \", \n",
    "      \"{:.0%}\".format(\n",
    "                      metrics.accuracy_score(y_test, y_pred)\n",
    "                      )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Анализ качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Допишите класс \"глупого классификатора\", что всегда предсказывает класс `0`. \n",
    "\n",
    "class DummyClassifier:\n",
    "    def __init__(self):\n",
    "        print('DummyClassifier is ready to work!')\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Должен возвращаться массив N предсказаний\n",
    "        N = x.shape[0]\n",
    "        return np.zeros(N)\n",
    "    \n",
    "        pass # если у фукнции или метода нет тела, то нужно писать pass, чтобы код скомпилировался"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier is ready to work!\n",
      "DummyClassifier's accuracy =  0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Оцените точность \"глупого классификатора\", объясните результат.\n",
    "lg_stupid = DummyClassifier()\n",
    "pred_stupid = lg_stupid.predict(x_test)\n",
    "print(\"DummyClassifier's accuracy = \", metrics.accuracy_score(y_test, pred_stupid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DummyClassifier's recall = 0.0 \n",
      " DummyClassifier's precision =  0.0 \n",
      " DummyClassifier's F1 =  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Используйте дополнительные метрики из пакета sklearn для анализа \"глупого классификатора\".\n",
    "# кроме accuracy, есть другие метрики анализа эффективности модели: recall, precision, f1\n",
    "lg_stupid_recall = metrics.recall_score(y_test, pred_stupid)\n",
    "lg_stupid_precision = metrics.precision_score(y_test, pred_stupid)\n",
    "lg_stupid_f1 = metrics.f1_score(y_test, pred_stupid)\n",
    "\n",
    "print(\" DummyClassifier's recall =\", lg_stupid_recall,\n",
    "     \"\\n DummyClassifier's precision = \", lg_stupid_precision,\n",
    "     \"\\n DummyClassifier's F1 = \", lg_stupid_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод: с DummyClassifier какие-то проблемы. Метрика Accuracy = 0,91. Более точные метрики дают 0. Скорее всего, 90% данных — это нули. Возможно, такая ситуация возникла из-за дисбаланса выборки, то есть из-за ситуации, когда в выборке экземпляторов класса 0 на порядок больше, чем экземляров класса 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "На протяжении этой лабораторной необходимо оценивать модели по 4 метрикам: accuracy, recall, precision, F1. \n",
    "Поэтому в целях упрощения кода и уменьшения его размера имеет смысл написать фукцию, которая будет принимать \n",
    "на вход y_test и y_predicted, \n",
    "на вывод выдавать значения четырех метрик.\n",
    "'''\n",
    "\n",
    "def main_metrics(y_test, y_pred):\n",
    "    model_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    model_recall = metrics.recall_score(y_test, y_pred)\n",
    "    model_precision = metrics.precision_score(y_test, y_pred)\n",
    "    model_f1 = metrics.f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\n accuracy =\",'{:.2f}'.format(model_accuracy),\n",
    "          \"\\n recall =\", '{:.2f}'.format(model_recall),\n",
    "         \"\\n precision = \", '{:.2f}'.format(model_precision),\n",
    "         \"\\n F1 = \", '{:.2f}'.format(model_f1)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier's metrics:\n",
      "\n",
      " accuracy = 0.96 \n",
      " recall = 0.70 \n",
      " precision =  0.82 \n",
      " F1 =  0.76\n"
     ]
    }
   ],
   "source": [
    "# Используя те же метрики, проанализируйте модель логистической регрессии. Объясните результат.\n",
    "print(\"DummyClassifier's metrics:\")\n",
    "main_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод: модель логистической регрессии работает лучше, чем DummyClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Анализ набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Кол-во экземпляров класса 0 =  200 \n",
      " Кол-во экземпляров класса 1 =  20\n"
     ]
    }
   ],
   "source": [
    "# Посчитайте количество экземпляров данных для каждого класса.\n",
    "print(\" Кол-во экземпляров класса 0 = \",  sum(y_train == 0), \n",
    "      \"\\n Кол-во экземпляров класса 1 = \", sum(y_train == 1)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lg_balanced metrics:\n",
      "\n",
      " accuracy = 0.96 \n",
      " recall = 0.75 \n",
      " precision =  0.83 \n",
      " F1 =  0.79\n"
     ]
    }
   ],
   "source": [
    "# Предложите способ улучшения качества модели. Подсказка: добавление дубликатов в данные.\n",
    "x_train_balanced = x_train[199:219]\n",
    "y_train_balanced = y_train[199:219]\n",
    "x_train_new = x_train\n",
    "y_train_new = y_train\n",
    "\n",
    "# Создайте и обучите модель с использованием предложенных наработок.\n",
    "for i in range(0,9):\n",
    "    x_train_new = np.concatenate((x_train_new, x_train_balanced))\n",
    "    y_train_new = np.concatenate((y_train_new, y_train_balanced))\n",
    "\n",
    "lg_balanced = LogisticRegression()\n",
    "lg_balanced.fit(x_train_new, y_train_new)\n",
    "lg_balanced_predict = lg_balanced.predict(x_test)\n",
    "\n",
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics. \n",
    "print(\"lg_balanced metrics:\")\n",
    "main_metrics(y_test, lg_balanced_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Применение логистической регрессии (нелинейные данные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите модель но этом наборе данных.\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        self.w = np.random.randn(dim, 1) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        x = x.dot(self.w) + self.b\n",
    "        p = sigmoid(x)\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "        \n",
    "    def fit(self, x, y, iters=100, lr=0.01):\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)\n",
    "lg = LogisticRegression()\n",
    "lg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-linear model's metrics:\n",
      "\n",
      " accuracy = 0.48 \n",
      " recall = 0.98 \n",
      " precision =  0.46 \n",
      " F1 =  0.63\n"
     ]
    }
   ],
   "source": [
    "# Проанализируйте качество модели.\n",
    "y_pred = lg.predict(x_test)\n",
    "\n",
    "print(\"Non-linear model's metrics:\")\n",
    "main_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING: попробуйте применить на исходных данных разные нелинейные функции (sin, tanh, x^2, ...).\n",
    "# Объедините трансформированные данные с исходными.\n",
    "x_train_new = np.concatenate((x_train, np.sin(x_train)), axis=1)\n",
    "#x_train_new = np.concatenate((x_train, x_train**2), axis=1)\n",
    "\n",
    "x_test_new = np.concatenate((x_test, np.sin(x_test)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> Если делать FEATURE ENGINEERING, то нужно добавлять новые признаки в `x_train`. Но нужно добавлять именно признаки `axis = 1`, но не эксзепляры `axis = 0`. Также если я сделать FEATURE ENGINEERING на тестовых данных `x_train`, то я должен также расширить пространство признаков для `x-test`, то есть сделать те же самые преобразования, которые я делал для `x-train`.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![help_image](help_from_mentor201022.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Создайте и обучите модель с использованием наработок.\n",
    "lg_new = LogisticRegression(x_train_new.shape[1])\n",
    "lg_new.fit(x_train_new, y_train)\n",
    "\n",
    "y_pred_new = lg_new.predict(x_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " accuracy = 0.86 \n",
      " recall = 0.69 \n",
      " precision =  1.00 \n",
      " F1 =  0.82\n"
     ]
    }
   ],
   "source": [
    "# Оцените качество новой модели, используя метрики из пакета sklearn.metrics. \n",
    "main_metrics(y_test, y_pred_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Доп. задания (любое на выбор, опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 'Упрощение' логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложность: легко."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модифицируйте класс логистической регрессии так, чтобы в нём не использовалась сигмоида.\n",
    "# То есть вывод о предсказанном классе должен делаться на основе значений \"до сигмоиды\".\n",
    "# Вспомогательная ссылка: https://en.wikipedia.org/wiki/Logit\n",
    "# Подсказка: взгляните на то, при каких входных `x` значение сигмоды больше 0.5 и меньше 0.5.\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, dim=2):\n",
    "        self.w = np.random.randn(dim, 1) / np.sqrt(dim)\n",
    "        self.b = np.zeros((1,))\n",
    "        \n",
    "    def predict(self, x, probs=False):\n",
    "        x = x.dot(self.w) + self.b\n",
    "        p = sigmoid(x)\n",
    "        if probs:\n",
    "            return p\n",
    "        return np.array(p > 0.5).astype('int32')\n",
    "        \n",
    "    def fit(self, x, y, iters=100, lr=0.01):\n",
    "        y = y.reshape(-1, 1)\n",
    "        for i in range(iters):\n",
    "            preds = self.predict(x, probs=True)\n",
    "            self.w -= lr * np.mean(x.T.dot(preds - y), axis=1, keepdims=True)\n",
    "            self.b -= lr * np.mean(preds - y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторите эксперимент из задания 1.\n",
    "x_train, y_train, x_test, y_test = load_data('dataset1')\n",
    "lg_3 = LogisticRegression(x_train.shape[1])\n",
    "lg_3.fit(x_train, y_train)\n",
    "\n",
    "y_pred_3 = lg_3.predict(x_test)\n",
    "\n",
    "print(\"Easy Log Regression model's metrics:\")\n",
    "main_metrics(y_test, y_pred_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 'Обобщение' логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите многоклассовый классификатор. Обучите его на наборе данных ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_data('dataset3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ансамбль логистических регрессий.</b> Сложность: супергерой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс, что инкапсулирует в себе `C` логистических регрессий, \n",
    "где `C` - количество классов. i-ая логистическая регрессия производит \n",
    "бинарную классификацию вида: все остальные классы и i-ый класс.\n",
    "\"\"\"\n",
    "\n",
    "class MulticlassLogisticRegression:\n",
    "    def __init__(self, n_classes, dim):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Возвращается массив целых чисел размерности [N],\n",
    "        # где i-ый элемент обозначает номер класса для \n",
    "        # i-го экземпляра данных в `x`.\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор. Оцените точность модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Softmax классификатор.</b> Сложность: математический гений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Напишите класс классификатора, основанного на функции Softmax.\n",
    "Алгоритм работы данного классификатора:\n",
    "x - вектор (экземпляр данных) размерности dim.\n",
    "W - матрица весов размерности [dim, n_classes].\n",
    "\n",
    "Ответ классификатора формируется как:\n",
    "logits = x * W - матричное умножение\n",
    "p = softmax(logits)\n",
    "class_id = argmax(p)\n",
    "\n",
    "Для данного классификатора требуется модифицировать алгоритм обучения в методе fit.\n",
    "\n",
    "Вспомогательные ресурсы:\n",
    "https://en.wikipedia.org/wiki/Softmax_function\n",
    "https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/\n",
    "\"\"\"\n",
    "\n",
    "class SoftmaxClassificator:\n",
    "    def __init__(self, n_classes, dim):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # x - numpy массив размерности [N, dim]\n",
    "        # Возвращается массив целых чисел размерности [N],\n",
    "        # где i-ый элемент обозначает номер класса для \n",
    "        # i-го экземпляра данных в `x`.\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор. Оцените точность модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте и обучите написанный классификатор на наборе данных из задания 1 (опционально). Оцените точность модели.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
